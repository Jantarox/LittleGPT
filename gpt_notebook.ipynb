{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f28abdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "\t\n",
      " !\"#%&'()*,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz ÓóĄąĆćĘęŁłŃńŚśŹźŻż̨́̇​﻿\n"
     ]
    }
   ],
   "source": [
    "def get_unique_chars(text):\n",
    "    return sorted(list(set(text)))\n",
    "\n",
    "\n",
    "with open(\"data/discopolo_songs_clean.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = get_unique_chars(text)\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(vocab_size)\n",
    "print(\"\".join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedc30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {char: idx for idx, char in enumerate(chars)}\n",
    "itos = {idx: char for idx, char in enumerate(chars)}\n",
    "\n",
    "encode = lambda string: [stoi[char] for char in string]\n",
    "decode = lambda tokens: \"\".join([itos[idx] for idx in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83d8fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2393177]) torch.int64\n",
      "tensor([48, 59, 65, 73, 74,  2, 70, 63, 69, 73, 59, 68, 65, 63, 26,  2, 29, 65,\n",
      "        57, 59, 68, 74,  9, 70, 66, 10,  2, 13,  2, 30, 63, 55, 91, 55,  2, 41,\n",
      "        59, 77, 55,  1, 17, 14,  2, 44, 69, 70, 72, 80, 59, 80,  2, 67, 69, 72,\n",
      "        80, 55,  2, 63,  2, 70, 72, 80, 59, 80,  2, 69, 57, 59, 55, 68, 79,  1,\n",
      "        70, 91, 79, 68, 63, 59,  2, 73, 74, 55, 74, 59, 65,  2, 77, 95, 72, 83,\n",
      "        58,  2, 77, 73, 70, 63, 59, 68, 63, 69, 68, 79, 57, 62,  2, 60, 55, 66,\n",
      "         1, 55,  2, 68, 55,  2, 73, 74, 55, 74, 65, 75,  2, 57, 62, 91, 69, 70,\n",
      "        55, 65,  2, 80, 55, 65, 69, 57, 62, 55, 68, 79,  2,  1, 80, 55, 65, 69,\n",
      "        57, 62, 55, 68, 79,  2, 77,  2,  2, 67, 69, 72, 80, 75,  2, 74, 79, 66,\n",
      "        59,  2, 66, 55, 74,  2,  1,  1, 46, 59, 60, 26, 78, 18,  1,  1, 30, 63,\n",
      "        55, 91, 55,  2, 67, 59, 77, 69, 12,  2, 66, 59, 87,  2, 58, 55, 66, 59,\n",
      "        65, 69,  2, 73, 74, 85, 58, 12,  1, 66, 59, 87,  2, 58, 55, 66, 59, 65,\n",
      "        69,  2, 68, 55,  2, 69, 64, 57, 80, 79, 80, 68, 79,  2, 66, 85, 58, 12,\n",
      "         1, 70, 69, 66, 59, 87, 12,  2, 70, 69, 77, 63, 59, 58, 80, 12,  2, 99,\n",
      "        59,  2, 67, 55, 72, 79, 68, 55, 72, 80,  2, 57, 62, 77, 55, 74, 12, 81,\n",
      "         1, 67, 69, 72, 80, 59,  2, 65, 69, 57, 62, 55,  2, 69, 58,  2, 58, 80,\n",
      "        63, 59, 57, 63, 68, 68, 79, 57, 62,  2, 66, 55, 74,  1,  1,  1, 18, 14,\n",
      "         2, 42, 55, 58,  2, 69, 65, 72, 59, 74, 59, 67,  2, 56, 63, 55, 91, 55,\n",
      "         2, 67, 59, 77, 55,  2, 66, 59, 57, 63,  2,  1, 68, 55, 58,  2, 70, 69,\n",
      "        58, 65, 91, 55, 58, 59, 67,  2, 61, 58, 80, 63, 59, 73,  2, 73, 63, 89,\n",
      "         2, 80, 59, 72, 77, 55, 91,  2, 77, 63, 55, 74, 72,  2,  1, 55,  2, 68,\n",
      "        55, 58,  2, 73, 74, 55, 74, 65, 63, 59, 67,  2, 57, 80, 55, 72, 68, 59,\n",
      "         2, 57, 62, 67, 75, 72, 79,  2, 77, 63, 73, 80, 85,  1, 55,  2, 67, 55,\n",
      "        72, 79, 68, 55, 72, 80,  2, 73, 77, 85,  2, 67, 59, 66, 69, 58, 63, 89,\n",
      "         2, 61, 72, 55,  2,  1,  1, 46, 59, 60, 14,  2, 18, 78,  1,  1, 19, 14,\n",
      "         2, 42, 55,  2, 69, 64, 57, 80, 79, 73, 74, 59, 64,  2, 80, 63, 59, 67,\n",
      "        63,  2, 70, 63, 69, 73, 65, 55,  2, 70, 55, 58, 91, 55,  2,  1, 56, 63,\n",
      "        55, 91, 55,  2, 67, 59, 77, 55,  2, 74, 59, 99,  2, 75, 70, 55, 58, 91,\n",
      "        55,  2, 77,  2, 70, 63, 55, 57, 62,  2,  1, 63,  2, 69,  2, 67, 55, 72,\n",
      "        79, 68, 55, 72, 80, 75,  2, 69, 70, 69, 77, 63, 55, 58, 55,  2,  1, 57,\n",
      "        69,  2, 68, 55,  2, 67, 69, 72, 80, 75,  2, 70, 72, 80, 59, 80, 79, 91,\n",
      "         2, 74, 79, 66, 59,  2, 66, 55, 74,  2,  1,  1, 46, 59, 60, 14,  2, 18,\n",
      "        78,  1, 70, 69, 66, 59, 57,  2, 14, 14, 14,  1,  1, 48, 59, 65, 73, 74,\n",
      "         2, 70, 63, 69, 73, 59, 68, 65, 63, 26,  2, 29, 65, 57, 59, 68, 74,  9,\n",
      "        70, 66, 10,  2, 13,  2, 30, 63, 69, 72, 89,  2, 75, 72, 66, 69, 70,  2,\n",
      "        69, 58,  2, 31, 63, 59, 56, 63, 59,  2, 18, 16, 17, 16,  1, 17, 14,  2,\n",
      "        31, 80, 55, 72, 68, 59,  2, 57, 62, 67, 75, 72, 79,  2, 68, 55, 58,  2,\n",
      "        68, 55, 67, 63,  1, 37, 73, 65, 72, 80, 85,  2, 56, 91, 79, 73, 65, 55,\n",
      "        77, 63, 57, 55, 67, 63,  1, 44, 69, 72, 55,  2, 73, 65, 69, 93, 57, 80,\n",
      "        79, 87,  2, 74, 89,  2, 67, 63, 91, 69, 95, 87,  1, 42, 63, 59,  2, 67,\n",
      "        55,  2, 57, 80, 59, 61, 69,  2, 72, 55, 74, 69, 77, 55, 87,  1, 42, 63,\n",
      "        59,  2, 67, 55,  2, 57, 80, 59, 61, 69,  2, 99, 55, 91, 69, 77, 55, 87,\n",
      "         1, 30, 79, 91, 69,  2, 63,  2, 73, 63, 89,  2, 73, 65, 69, 93, 57, 80,\n",
      "        79, 91, 69,  1, 42, 63, 57,  2, 67, 68, 63, 59,  2, 74, 59, 72, 55, 80,\n",
      "         2, 68, 63, 59,  2, 74, 72, 80, 79, 67, 55,  1, 54, 56, 79, 74,  2, 68,\n",
      "        59, 72, 77, 69, 77, 79,  2, 64, 59, 73, 74,  2, 65, 66, 63, 67, 55, 74,\n",
      "         1, 47, 74, 69,  2, 77, 79, 67, 83, 77, 59, 65,  2, 63,  2, 73, 70, 69,\n",
      "        72, 83, 77,  1, 32, 69, 73, 79, 87,  2, 67, 55, 67,  2, 48, 77, 69, 64,\n",
      "        59, 64,  2, 80, 91, 69, 95, 57, 63,  1, 37,  2, 74, 69, 65, 73, 79, 57,\n",
      "        80, 68, 59, 64,  2, 80, 55, 80, 58, 72, 69, 95, 57, 63,  1, 32, 69, 95,\n",
      "        87,  2, 73, 55, 67, 69, 74, 68, 79, 57, 62,  2, 77, 63, 59, 57, 80, 69,\n",
      "        72, 83, 77,  1,  1, 46, 59, 60, 26,  2, 30, 63, 69, 72, 89,  2, 75, 72,\n",
      "        66, 69, 70,  2, 69, 58,  2, 31, 63, 59, 56, 63, 59,  1, 31, 62, 57, 89,\n",
      "         2, 56, 79, 87,  2, 64, 55, 65,  2, 77,  2, 68, 63, 59, 56, 63, 59,  1,\n",
      "        51, 63, 89, 57,  2, 99, 59, 61, 68, 55, 64,  2, 65, 69, 57, 62, 55, 68,\n",
      "        63, 59,  1, 30, 63, 69, 72, 89,  2, 77])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923902f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48, 59, 65, 73, 74,  2, 70, 63, 69])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_idx = int(len(data) * 0.9)\n",
    "train_data = data[:split_idx]\n",
    "val_data = data[split_idx:]\n",
    "\n",
    "block_size = 8\n",
    "train_data[: block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d148c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([48]) the target: 59\n",
      "when input is tensor([48, 59]) the target: 65\n",
      "when input is tensor([48, 59, 65]) the target: 73\n",
      "when input is tensor([48, 59, 65, 73]) the target: 74\n",
      "when input is tensor([48, 59, 65, 73, 74]) the target: 2\n",
      "when input is tensor([48, 59, 65, 73, 74,  2]) the target: 70\n",
      "when input is tensor([48, 59, 65, 73, 74,  2, 70]) the target: 63\n",
      "when input is tensor([48, 59, 65, 73, 74,  2, 70, 63]) the target: 69\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1 : block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d9a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[68, 55, 67, 63,  1, 41, 55, 74],\n",
      "        [77, 63, 59, 57, 85,  2, 64, 55],\n",
      "        [65, 73, 74,  2, 70, 63, 69, 73],\n",
      "        [67, 68, 63, 59,  1, 54, 55, 65]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[55, 67, 63,  1, 41, 55, 74, 65],\n",
      "        [63, 59, 57, 85,  2, 64, 55, 65],\n",
      "        [73, 74,  2, 70, 63, 69, 73, 59],\n",
      "        [68, 63, 59,  1, 54, 55, 65, 69]])\n",
      "----\n",
      "when input is [68] the target: 55\n",
      "when input is [68, 55] the target: 67\n",
      "when input is [68, 55, 67] the target: 63\n",
      "when input is [68, 55, 67, 63] the target: 1\n",
      "when input is [68, 55, 67, 63, 1] the target: 41\n",
      "when input is [68, 55, 67, 63, 1, 41] the target: 55\n",
      "when input is [68, 55, 67, 63, 1, 41, 55] the target: 74\n",
      "when input is [68, 55, 67, 63, 1, 41, 55, 74] the target: 65\n",
      "when input is [77] the target: 63\n",
      "when input is [77, 63] the target: 59\n",
      "when input is [77, 63, 59] the target: 57\n",
      "when input is [77, 63, 59, 57] the target: 85\n",
      "when input is [77, 63, 59, 57, 85] the target: 2\n",
      "when input is [77, 63, 59, 57, 85, 2] the target: 64\n",
      "when input is [77, 63, 59, 57, 85, 2, 64] the target: 55\n",
      "when input is [77, 63, 59, 57, 85, 2, 64, 55] the target: 65\n",
      "when input is [65] the target: 73\n",
      "when input is [65, 73] the target: 74\n",
      "when input is [65, 73, 74] the target: 2\n",
      "when input is [65, 73, 74, 2] the target: 70\n",
      "when input is [65, 73, 74, 2, 70] the target: 63\n",
      "when input is [65, 73, 74, 2, 70, 63] the target: 69\n",
      "when input is [65, 73, 74, 2, 70, 63, 69] the target: 73\n",
      "when input is [65, 73, 74, 2, 70, 63, 69, 73] the target: 59\n",
      "when input is [67] the target: 68\n",
      "when input is [67, 68] the target: 63\n",
      "when input is [67, 68, 63] the target: 59\n",
      "when input is [67, 68, 63, 59] the target: 1\n",
      "when input is [67, 68, 63, 59, 1] the target: 54\n",
      "when input is [67, 68, 63, 59, 1, 54] the target: 55\n",
      "when input is [67, 68, 63, 59, 1, 54, 55] the target: 65\n",
      "when input is [67, 68, 63, 59, 1, 54, 55, 65] the target: 69\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4  # how many independent sequences will we process in parallel?\n",
    "block_size = 8  # what is the maximum context length for predictions?\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "for b in range(batch_size):  # batch dimension\n",
    "    for t in range(block_size):  # time dimension\n",
    "        context = xb[b, : t + 1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec8b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 105])\n",
      "tensor(5.2934, grad_fn=<NllLossBackward0>)\n",
      "\tCżbsAsKĆMmfOń33!'ŚH5įH​0 tżć% ́fąNŚÓRSaljMALÓblCd/g4)'źjlk5a/9y​\"\trEvbwEą3p\n",
      "!tk59WṔV;#4jŻXhURą2Vś3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # botch idx and targets are of size (B, T)\n",
    "        logits = self.token_embedding_table(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape  # Batch, Tokens (block_size), Channels (vocab_size)\n",
    "\n",
    "            # F.cross_entropy() expects dims (Batch, Channels, ...) or (Batch, Channels)\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, _ = self(idx)  # (B, T, C)\n",
    "            # we currently only care about last token\n",
    "            logits = logits[:, -1, :]  # now (B, C)\n",
    "\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample\n",
    "            pred_idx = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "\n",
    "            idx = torch.cat((idx, pred_idx), dim=1)\n",
    "\n",
    "        return idx\n",
    "\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model(xb, yb)\n",
    "\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "pred_idxs = model.generate(\n",
    "    idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100\n",
    ")\n",
    "decoded_tokens = decode(pred_idxs[0].tolist())\n",
    "print(decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e15a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d797f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Loss=2.691286087036133\n",
      "Step 1000: Loss=2.752305507659912\n",
      "Step 2000: Loss=2.6109378337860107\n",
      "Step 3000: Loss=2.5512685775756836\n",
      "Step 4000: Loss=2.5911865234375\n",
      "Step 5000: Loss=2.606036424636841\n",
      "Step 6000: Loss=2.569638729095459\n",
      "Step 7000: Loss=2.5174143314361572\n",
      "Step 8000: Loss=2.490147590637207\n",
      "Step 9000: Loss=2.504244089126587\n",
      "2.6217947006225586\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(10000):  # increase number of steps for good results...\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if steps % 1000 == 0:\n",
    "        print(f\"Step {steps}: Loss={loss}\")\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20b05a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCYGdy sić miowemni gniest \n",
      "I\"Byasz dy klemiekokoch pią, !)\n",
      "\n",
      "po tościodadawabiepe  niajm sk gdź kosze\n"
     ]
    }
   ],
   "source": [
    "pred_idxs = model.generate(\n",
    "    idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100\n",
    ")\n",
    "decoded_tokens = decode(pred_idxs[0].tolist())\n",
    "print(decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6acf889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"--\")\n",
    "print(\"b=\")\n",
    "print(b)\n",
    "print(\"--\")\n",
    "print(\"c=\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cd8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2  # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31c9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1808, -0.0700],\n",
      "         [-0.0894, -0.4926],\n",
      "         [ 0.1490, -0.3199],\n",
      "         [ 0.3504, -0.2238],\n",
      "         [ 0.3525,  0.0545],\n",
      "         [ 0.0688, -0.0396],\n",
      "         [ 0.0927, -0.0682],\n",
      "         [-0.0341,  0.1332]],\n",
      "\n",
      "        [[ 1.3488, -0.1396],\n",
      "         [ 0.8173,  0.4127],\n",
      "         [-0.1342,  0.4395],\n",
      "         [ 0.2711,  0.4774],\n",
      "         [ 0.2421,  0.0694],\n",
      "         [ 0.0084,  0.0020],\n",
      "         [ 0.0712, -0.1128],\n",
      "         [ 0.2527,  0.2149]],\n",
      "\n",
      "        [[-0.6631, -0.2513],\n",
      "         [ 0.1735, -0.0649],\n",
      "         [ 0.1685,  0.3348],\n",
      "         [-0.1621,  0.1765],\n",
      "         [-0.2312, -0.0436],\n",
      "         [-0.1015, -0.2855],\n",
      "         [-0.2593, -0.1630],\n",
      "         [-0.3015, -0.2293]],\n",
      "\n",
      "        [[ 1.6455, -0.8030],\n",
      "         [ 1.4985, -0.5395],\n",
      "         [ 0.4954,  0.3420],\n",
      "         [ 1.0623, -0.1802],\n",
      "         [ 1.1401, -0.4462],\n",
      "         [ 1.0870, -0.4071],\n",
      "         [ 1.0430, -0.1299],\n",
      "         [ 1.1138, -0.1641]]])\n"
     ]
    }
   ],
   "source": [
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, : t + 1]  # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, dim=0)\n",
    "\n",
    "print(xbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f49d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x\n",
    "torch.allclose(xbow, xbow2, atol=1e-07)  # had to lower tollerance from 1e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e918bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3, atol=1e-07)  # had to lower tollerance from 1e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3024ed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32  # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "q = query(x)\n",
    "k = key(x)\n",
    "wei = q @ k.transpose(-2, -1) / head_size**0.5  # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d329511b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5221, 0.4779, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3602, 0.3210, 0.3188, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2980, 0.4039, 0.1578, 0.1404, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1643, 0.1243, 0.1678, 0.1865, 0.3570, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2656, 0.2110, 0.1137, 0.1214, 0.2018, 0.0865, 0.0000, 0.0000],\n",
       "        [0.1761, 0.1327, 0.1371, 0.0974, 0.1476, 0.1918, 0.1173, 0.0000],\n",
       "        [0.1046, 0.1260, 0.0922, 0.0906, 0.1476, 0.1588, 0.1432, 0.1371]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6705e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b65076a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0739)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9e1ef9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8914)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6170b26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.5060)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "45a66b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8441)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = q @ k.transpose(-2, -1) / head_size**0.5\n",
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "44494bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800ea61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5939e-03, 1.3117e-05, 3.9102e-02, 1.3117e-05, 9.5928e-01])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High variance causes the tensor after softmax to converge to one-hot\n",
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]) * head_size, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d03847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d:  # (used to be BatchNorm1d)\n",
    "\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        xmean = x.mean(1, keepdim=True)  # batch mean\n",
    "        xvar = x.var(1, keepdim=True)  # batch variance\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)  # normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100)  # batch size 32 of 100-dimensional vectors\n",
    "x1 = module(x)\n",
    "x2 = torch.nn.LayerNorm((100,))(x)\n",
    "\n",
    "x1.shape\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c2cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8899))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:, 0].mean(), x[:, 0].std()  # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88619f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0476))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0, :].mean(), x[\n",
    "    0, :\n",
    "].std()  # mean,std of a single input from the batch, of its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f5003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1476, grad_fn=<MeanBackward0>), tensor(0.8899))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[:, 0].mean(), x[:, 0].std()  # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3635998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.4305e-08, grad_fn=<MeanBackward0>), tensor(1.0476))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[0, :].mean(), x[0, :].std()  # mean,std of one feature across all batch inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
